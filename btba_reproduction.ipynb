{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4",
      "mount_file_id": "132s9GYcx6ab5EY4Y8ZA_e3aBdwtdOQ6N",
      "authorship_tag": "ABX9TyNetsCa4TS8fEEQO1osq9k6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ac685f4372f3409eb28a37af38f10994": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d3b61e7cd74d4717b8cfec3ee6f3c83b",
              "IPY_MODEL_0fa27f80a1be45808fe760d6a854aa8a",
              "IPY_MODEL_dfc99f599db545b2b6d970dd7add0145"
            ],
            "layout": "IPY_MODEL_0b694989fb75498580950ef0b7d0befb"
          }
        },
        "d3b61e7cd74d4717b8cfec3ee6f3c83b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8ecfc3ca273b48ca8f52bee363787d29",
            "placeholder": "​",
            "style": "IPY_MODEL_36df467091864a90a24848057f19426e",
            "value": "config.json: 100%"
          }
        },
        "0fa27f80a1be45808fe760d6a854aa8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d59b176c198d4bbf89cd8c70c18f1064",
            "max": 1628,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_739a10bb3ba44d1ea8afd15be7d861d6",
            "value": 1628
          }
        },
        "dfc99f599db545b2b6d970dd7add0145": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c552229d16744199bf26a24d23b71a80",
            "placeholder": "​",
            "style": "IPY_MODEL_a3efb5058d134c0d9d0e728516236dc2",
            "value": " 1.63k/1.63k [00:00&lt;00:00, 127kB/s]"
          }
        },
        "0b694989fb75498580950ef0b7d0befb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8ecfc3ca273b48ca8f52bee363787d29": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "36df467091864a90a24848057f19426e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d59b176c198d4bbf89cd8c70c18f1064": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "739a10bb3ba44d1ea8afd15be7d861d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c552229d16744199bf26a24d23b71a80": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a3efb5058d134c0d9d0e728516236dc2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "93f8e63a111b43978dc59cc0d19f8b8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_715996bfae3341f1bd6b22acb4b0ceb0",
              "IPY_MODEL_580b6c7a96654ed0834d8782f88b07aa",
              "IPY_MODEL_59ae5b46631146a888df73cc5dee286a"
            ],
            "layout": "IPY_MODEL_e4aac4eafe40447ab93159895f9f5a01"
          }
        },
        "715996bfae3341f1bd6b22acb4b0ceb0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7de9ca9717df44eeac256ac3b5107752",
            "placeholder": "​",
            "style": "IPY_MODEL_fb9815f28617477b9e8b55118a81f3e1",
            "value": "config.json: 100%"
          }
        },
        "580b6c7a96654ed0834d8782f88b07aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e3fbd6a8262f4a50b791531ddd92925d",
            "max": 1628,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cdffc55320a64dd683660dfb0130b6b4",
            "value": 1628
          }
        },
        "59ae5b46631146a888df73cc5dee286a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_451421c0edd142d58ef3f1f67ab501e3",
            "placeholder": "​",
            "style": "IPY_MODEL_03d3a268ec7b48a1b9f8aac570a18352",
            "value": " 1.63k/1.63k [00:00&lt;00:00, 120kB/s]"
          }
        },
        "e4aac4eafe40447ab93159895f9f5a01": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7de9ca9717df44eeac256ac3b5107752": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fb9815f28617477b9e8b55118a81f3e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e3fbd6a8262f4a50b791531ddd92925d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cdffc55320a64dd683660dfb0130b6b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "451421c0edd142d58ef3f1f67ab501e3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "03d3a268ec7b48a1b9f8aac570a18352": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "272a680d71924bc9b19706222ea0e73a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7dece1c9e4ea44ba9f78346ba6246274",
              "IPY_MODEL_5be28e731cde40e482f3e7f67ddb60f3",
              "IPY_MODEL_b684fe1ef2204f2a80f849556be010b1"
            ],
            "layout": "IPY_MODEL_9950ec2dd4d346e28fd65c626f3cf621"
          }
        },
        "7dece1c9e4ea44ba9f78346ba6246274": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_09a6ba553b2447a59876246a2c8e7ee7",
            "placeholder": "​",
            "style": "IPY_MODEL_a02215234a0948ae8bdff0a1ad5dc17c",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "5be28e731cde40e482f3e7f67ddb60f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_25f268aea571434b93edb039cee36fa9",
            "max": 1018571383,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4f2d81a528484ab4a7d1f2a48d049eb7",
            "value": 1018571383
          }
        },
        "b684fe1ef2204f2a80f849556be010b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3991e2a817034e47815ce5370cd9fb80",
            "placeholder": "​",
            "style": "IPY_MODEL_3d4148ad975a4e5fbafbc946367051c1",
            "value": " 1.02G/1.02G [00:03&lt;00:00, 283MB/s]"
          }
        },
        "9950ec2dd4d346e28fd65c626f3cf621": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "09a6ba553b2447a59876246a2c8e7ee7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a02215234a0948ae8bdff0a1ad5dc17c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "25f268aea571434b93edb039cee36fa9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4f2d81a528484ab4a7d1f2a48d049eb7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3991e2a817034e47815ce5370cd9fb80": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3d4148ad975a4e5fbafbc946367051c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CaptainPlusPlus/btba_reproduction/blob/main/btba_reproduction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Reproduction of BTBA Model for Unsupervised Word Alignment\n",
        "Article can be found here: https://aclanthology.org/2021.acl-long.24.pdf\n",
        "\n",
        "This reproduction offers a modification of the original transformer model as well as BART using the architecture enhancment for unsupervised learning of the alignment task as described in the article."
      ],
      "metadata": {
        "id": "ExMtdui5y-3a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Requirements\n",
        "* Downloand and preprocess the deen, fren, roen texts from https://github.com/lilt/alignment-scripts.\n",
        "* Upload the `bpe` lowercased preprocessed `train` & `test` folders as well as the sentencepiece `bpe` models."
      ],
      "metadata": {
        "id": "SmCCmEo3yXov"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Custom Tokenizer Definition\n",
        "\n",
        "Since the Sentencepiece tokenizer used in the article and alignment scripts it is compared against outputs a binary format model and vocabulary, the sentencepiece tokenizer must be adjusted to fit the HuggingFace models used to reproduce the article's transformer based approaach."
      ],
      "metadata": {
        "id": "Ap-m1E74yOte"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0_1oRQYyyGXl"
      },
      "outputs": [],
      "source": [
        "import sentencepiece as spm\n",
        "\n",
        "class CustomSentencePieceTokenizer:\n",
        "    def __init__(self, sentencepiece_model_path):\n",
        "        self.sp = spm.SentencePieceProcessor()\n",
        "        if not self.sp.Load(sentencepiece_model_path):\n",
        "            raise FileNotFoundError(\"Failed to load SentencePiece model from specified path.\")\n",
        "        self.special_tokens = {'<s>': self.sp.piece_to_id('<s>'), '</s>': self.sp.piece_to_id('</s>'), '<unk>': self.sp.piece_to_id('<unk>')}\n",
        "        self.additional_special_tokens = {'<pad>': self.sp.GetPieceSize(), '<mask>': self.sp.GetPieceSize() + 1}\n",
        "        self.special_token_ids = {**self.special_tokens, **self.additional_special_tokens}\n",
        "\n",
        "    def tokenize(self, text):\n",
        "        return self.sp.encode_as_pieces(text)\n",
        "\n",
        "    def convert_tokens_to_ids(self, tokens):\n",
        "        return [self.special_token_ids.get(token, self.sp.piece_to_id(token)) for token in tokens]\n",
        "\n",
        "    def convert_ids_to_tokens(self, ids):\n",
        "        id_to_token_map = {id: token for token, id in self.special_token_ids.items()}\n",
        "        id_to_token_map.update({id: self.sp.id_to_piece(id) for id in range(self.sp.GetPieceSize())})\n",
        "        return [id_to_token_map.get(id, '<unk>') for id in ids]\n",
        "\n",
        "    def get_vocab_size(self):\n",
        "        return self.sp.GetPieceSize() + len(self.additional_special_tokens)\n",
        "\n",
        "    def get_special_tokens(self):\n",
        "        return {**self.special_tokens, **self.additional_special_tokens}\n",
        "\n",
        "    def get_special_token_ids(self):\n",
        "        return self.special_token_ids\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tokenizer for BART without modifications"
      ],
      "metadata": {
        "id": "x7dm3wN74MSp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BartForConditionalGeneration, Trainer, TrainingArguments\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "import torch\n",
        "import sentencepiece as spm\n",
        "\n",
        "class CustomSentencePieceTokenizer:\n",
        "    def __init__(self, sentencepiece_model_path):\n",
        "        self.sp = spm.SentencePieceProcessor()\n",
        "        if not self.sp.Load(sentencepiece_model_path):\n",
        "            raise FileNotFoundError(\"Failed to load SentencePiece model from specified path.\")\n",
        "        self.special_tokens = {'<pad>': self.sp.piece_to_id('<pad>'), '<mask>': self.sp.piece_to_id('<mask>'), '<eos>': self.sp.piece_to_id('<eos>')}\n",
        "        self.additional_special_tokens = {'<bos>': self.sp.GetPieceSize(), '<sep>': self.sp.GetPieceSize() + 1}\n",
        "        self.special_token_ids = {**self.special_tokens, **self.additional_special_tokens}\n",
        "\n",
        "    def tokenize(self, text):\n",
        "        return self.sp.encode_as_pieces(text)\n",
        "\n",
        "    def convert_tokens_to_ids(self, tokens):\n",
        "        return [self.special_token_ids.get(token, self.sp.piece_to_id(token)) for token in tokens]\n",
        "\n",
        "    def convert_ids_to_tokens(self, ids):\n",
        "        id_to_token_map = {id: token for token, id in self.special_token_ids.items()}\n",
        "        id_to_token_map.update({id: self.sp.id_to_piece(id) for id in range(self.sp.GetPieceSize())})\n",
        "        return [id_to_token_map.get(id, '<unk>') for id in ids]\n",
        "\n",
        "    def get_vocab_size(self):\n",
        "        return self.sp.GetPieceSize() + len(self.additional_special_tokens)\n",
        "\n",
        "    def get_special_tokens(self):\n",
        "        return {**self.special_tokens, **self.additional_special_tokens}\n",
        "\n",
        "    def get_special_token_ids(self):\n",
        "        return self.special_token_ids\n",
        "\n",
        "    def pad_token_id(self):\n",
        "        return self.special_token_ids['<pad>']"
      ],
      "metadata": {
        "id": "USh47nRzz1IY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_custom_tokenizer():\n",
        "    tokenizer = CustomSentencePieceTokenizer('<PATH TO SENTENCEPIECE TRAIN MODEL FROM SOURCE OF PAIR>')\n",
        "    test_sentence = \"das ist ein test.\"\n",
        "    print(\"Testing tokenization of sentence:\", test_sentence)\n",
        "    tokens = tokenizer.tokenize(test_sentence)\n",
        "    print(\"Tokens:\", tokens)\n",
        "    token_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "    print(\"Token IDs:\", token_ids)\n",
        "    tokens_from_ids = tokenizer.convert_ids_to_tokens(token_ids)\n",
        "    print(\"Tokens from IDs:\", tokens_from_ids)\n",
        "    print(\"Special Tokens:\", tokenizer.get_special_tokens())\n",
        "    print(\"Special Token IDs:\", tokenizer.get_special_token_ids())\n",
        "    special_tokens_test = ['<pad>', '<mask>', '<s>', '</s>', '<unk>']\n",
        "    special_tokens_ids = tokenizer.convert_tokens_to_ids(special_tokens_test)\n",
        "    print(\"Special tokens to IDs:\", list(zip(special_tokens_test, special_tokens_ids)))\n",
        "    special_tokens_round_trip = tokenizer.convert_ids_to_tokens(special_tokens_ids)\n",
        "    print(\"IDs back to special tokens:\", special_tokens_round_trip)\n",
        "\n",
        "test_custom_tokenizer()"
      ],
      "metadata": {
        "id": "vu6WLpwz04Jc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "643e231a-3202-429f-dbb3-135b207e1b48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing tokenization of sentence: das ist ein test.\n",
            "Tokens: ['▁das', '▁ist', '▁ein', '▁test', '.']\n",
            "Token IDs: [94, 158, 69, 4218, 39789]\n",
            "Tokens from IDs: ['▁das', '▁ist', '▁ein', '▁test', '.']\n",
            "Special Tokens: {'<pad>': 0, '<mask>': 0, '<eos>': 0, '<bos>': 40000, '<sep>': 40001}\n",
            "Special Token IDs: {'<pad>': 0, '<mask>': 0, '<eos>': 0, '<bos>': 40000, '<sep>': 40001}\n",
            "Special tokens to IDs: [('<pad>', 0), ('<mask>', 0), ('<s>', 1), ('</s>', 2), ('<unk>', 0)]\n",
            "IDs back to special tokens: ['<unk>', '<unk>', '<s>', '</s>', '<unk>']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = CustomSentencePieceTokenizer('PATH TO SENTENCEPIECE TRAIN MODEL FROM SOURCE OF PAIR')"
      ],
      "metadata": {
        "id": "3WFG1iWM0xq7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load bpe lowercased data and save tokenized data\n",
        "Load data, tokenize data and save it to file (so that subsequent runs don't have to reload data)"
      ],
      "metadata": {
        "id": "-58ExfKzz-QH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "def load_data(src_file, tgt_file):\n",
        "    with open(src_file, 'r', encoding='utf-8') as src_f, open(tgt_file, 'r', encoding='utf-8') as tgt_f:\n",
        "        src_lines = [line.strip() for line in src_f.readlines()]\n",
        "        tgt_lines = [line.strip() for line in tgt_f.readlines()]\n",
        "    assert len(src_lines) == len(tgt_lines), \"Source and target files should have the same number of lines.\"\n",
        "    return src_lines, tgt_lines\n",
        "\n",
        "def tokenize_and_save_data(src_lines, tgt_lines, tokenizer, src_path, tgt_path):\n",
        "    tokenized_src = [torch.tensor(tokenizer.convert_tokens_to_ids(tokenizer.tokenize(line)), dtype=torch.long) for line in src_lines]\n",
        "    tokenized_tgt = [torch.tensor(tokenizer.convert_tokens_to_ids(tokenizer.tokenize(line)), dtype=torch.long) for line in tgt_lines]\n",
        "    torch.save(tokenized_src, src_path)\n",
        "    torch.save(tokenized_tgt, tgt_path)\n",
        "    print(f\"Tokenized data saved to {src_path} and {tgt_path}\")\n"
      ],
      "metadata": {
        "id": "mVWKvpQUz81I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define paths to data here after preprocessing"
      ],
      "metadata": {
        "id": "iKkWyViO80bg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "src_file_path = '<PATH TO SRC TRAIN, BPE LOWERCASE FORMAT>'\n",
        "tgt_file_path = '<PATH TO TARGET TRAIN, BPE LOWERCASE FORMAT>'\n",
        "model_path = '<PATH TO BPE SENTENCEPIECE TRAIN MODEL, BINARY>'\n",
        "tokenized_src_path = '<PATH TO SAVE/LOAD TOKENIZED SRC TRAIN DATA>'\n",
        "tokenized_tgt_path = '<PATH TO SAVE/LOAD TOKENIZED TARGERT TRAIN DATA>'\n",
        "\n",
        "eval_src_path = '<PATH TO SRC EVAL, BPE LOWERCASE FORMAT>'\n",
        "eval_tgt_path = '<PATH TO TARGET EVAL, BPE LOWERCASE FORMAT>'\n",
        "tokenized_eval_src_path = '<PATH TO SAVE/LOAD TOKENIZED SRC EVAL DATA>'\n",
        "tokenized_eval_tgt_path = '<PATH TO SAVE/LOAD TOKENIZED TARGET EVAL DATA>'"
      ],
      "metadata": {
        "id": "AQL1Hr350ns3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load and tokenize training and evaluation data"
      ],
      "metadata": {
        "id": "91RYTfl-9I-K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "src_lines, tgt_lines = load_data(src_file_path, tgt_file_path)\n",
        "tokenize_and_save_data(src_lines, tgt_lines, tokenizer, tokenized_src_path, tokenized_tgt_path)"
      ],
      "metadata": {
        "id": "aT-0iR8mtb-Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "src_lines, tgt_lines = load_data(eval_src_path, eval_tgt_path)\n",
        "tokenize_and_save_data(src_lines, tgt_lines, tokenizer, tokenized_eval_src_path, tokenized_eval_tgt_path)"
      ],
      "metadata": {
        "id": "FRkHOJ0M8l6f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dynamic Masking for tje Dataset\n",
        "\n",
        "* Every word in a sentence should be masked only once across the entire training - track the masking state and reset it after each epoch.\n",
        "* Percentage-based: At least 10% of the words in each sentence must be masked, or one word if the sentence has less than ten words."
      ],
      "metadata": {
        "id": "ImlkdDaf19vs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "class DynamicMaskingDataset(Dataset):\n",
        "    def __init__(self, tokenized_src, tokenized_tgt, tokenizer, mask_probability=0.1):\n",
        "        self.tokenized_src = tokenized_src\n",
        "        self.tokenized_tgt = tokenized_tgt\n",
        "        self.tokenizer = tokenizer\n",
        "        self.mask_id = tokenizer.get_special_token_ids()['<mask>']\n",
        "        self.pad_id = tokenizer.get_special_token_ids()['<pad>']\n",
        "        self.mask_probability = mask_probability\n",
        "        self.mask_tracker = {i: set() for i in range(len(tokenized_tgt))}\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.tokenized_tgt)\n",
        "\n",
        "    def reset_mask_tracker(self):\n",
        "        self.mask_tracker = {i: set() for i in range(len(self.tokenized_tgt))}\n",
        "\n",
        "    def mask_input(self, inputs, idx):\n",
        "        num_tokens = len(inputs)\n",
        "        num_to_mask = max(int(num_tokens * self.mask_probability), 1)\n",
        "        labels = inputs.clone()\n",
        "        candidate_mask = (inputs != self.pad_id) & (inputs != self.tokenizer.get_special_token_ids()['<s>']) & (inputs != self.tokenizer.get_special_token_ids()['</s>'])\n",
        "        candidate_indices = np.setdiff1d(np.where(candidate_mask.numpy())[0], list(self.mask_tracker[idx]))\n",
        "\n",
        "        if len(candidate_indices) == 0:\n",
        "            self.mask_tracker[idx] = set()\n",
        "            candidate_indices = np.where(candidate_mask.numpy())[0]\n",
        "\n",
        "        if len(candidate_indices) < num_to_mask:\n",
        "            num_to_mask = len(candidate_indices)\n",
        "\n",
        "        if num_to_mask > 0:\n",
        "            masked_indices = np.random.choice(candidate_indices, size=num_to_mask, replace=False)\n",
        "            self.mask_tracker[idx].update(masked_indices)\n",
        "            inputs[masked_indices] = self.mask_id\n",
        "        else:\n",
        "            labels.fill_(-100)\n",
        "\n",
        "        labels[~candidate_mask] = -100\n",
        "        return inputs, labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        src = self.tokenized_src[idx]\n",
        "        tgt = self.tokenized_tgt[idx]\n",
        "        src, src_labels = self.mask_input(src, idx)\n",
        "        tgt, tgt_labels = self.mask_input(tgt, idx)\n",
        "\n",
        "        return {\"input_ids\": src, \"labels\": tgt_labels}\n"
      ],
      "metadata": {
        "id": "l-JX0jEF1813"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load tokenized data and and predefine to mask dynamically"
      ],
      "metadata": {
        "id": "KYvrg5Gp9WTW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_src = torch.load(tokenized_src_path)\n",
        "tokenized_tgt = torch.load(tokenized_tgt_path)"
      ],
      "metadata": {
        "id": "S480mEuc2s-b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_eval_src = torch.load(tokenized_eval_src_path)\n",
        "tokenized_eval_tgt = torch.load(tokenized_eval_tgt_path)"
      ],
      "metadata": {
        "id": "Ldsc_DHI9AH_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = DynamicMaskingDataset(tokenized_src, tokenized_tgt, tokenizer)"
      ],
      "metadata": {
        "id": "HJmML1Ly-nQk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## For UNMODIFIED BART - load non masked dataset without collate"
      ],
      "metadata": {
        "id": "7PaRG7iw9jc2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, tokenized_src, tokenized_tgt):\n",
        "        self.tokenized_src = tokenized_src\n",
        "        self.tokenized_tgt = tokenized_tgt\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.tokenized_src)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        src = self.tokenized_src[idx]\n",
        "        tgt = self.tokenized_tgt[idx]\n",
        "        return {\"input_ids\": src, \"labels\": tgt}"
      ],
      "metadata": {
        "id": "tUAT-VPsz-8n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = SimpleDataset(tokenized_src, tokenized_tgt)\n"
      ],
      "metadata": {
        "id": "tcs7kNKTv9RW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eval_dataset = SimpleDataset(tokenized_eval_src, tokenized_eval_tgt)"
      ],
      "metadata": {
        "id": "b2NK1x4U9HKX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modigy BART according to BTBA architecture\n",
        "* Remove final feed forward sublayer in the last decoder layer.\n",
        "* Adjust model to initialize properly with these changes, padding to accomodate for masking is done in \"collate\""
      ],
      "metadata": {
        "id": "xk1GvYRi9vsm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BartConfig, BartModel\n",
        "import torch.nn as nn\n",
        "\n",
        "class BTBADecoderLayer(nn.Module):\n",
        "    def __init__(self, config, is_last_layer=False):\n",
        "        super().__init__()\n",
        "        self.self_attn = nn.MultiheadAttention(config.d_model, config.decoder_attention_heads)\n",
        "        self.multihead_attn = nn.MultiheadAttention(config.d_model, config.decoder_attention_heads)\n",
        "        self.layer_norm1 = nn.LayerNorm(config.d_model)\n",
        "        self.layer_norm2 = nn.LayerNorm(config.d_model)\n",
        "        self.is_last_layer = is_last_layer\n",
        "        if not is_last_layer:\n",
        "            self.ffn = nn.Sequential(\n",
        "                nn.Linear(config.d_model, config.decoder_ffn_dim),\n",
        "                nn.ReLU(),\n",
        "                nn.Linear(config.decoder_ffn_dim, config.d_model),\n",
        "            )\n",
        "        self.dropout = nn.Dropout(config.dropout)\n",
        "\n",
        "    def forward(self, x, memory, src_mask=None, tgt_mask=None):\n",
        "        x = self.layer_norm1(x + self.dropout(self.self_attn(x, x, x, key_padding_mask=tgt_mask)[0]))\n",
        "        x = self.layer_norm2(x + self.dropout(self.multihead_attn(x, memory, memory, key_padding_mask=src_mask)[0]))\n",
        "        if not self.is_last_layer:\n",
        "            x = self.ffn(x)\n",
        "        return x\n",
        "\n",
        "class BTBAModel(BartModel):\n",
        "    def __init__(self, config):\n",
        "        super().__init__(config)\n",
        "        self.decoder.layers = nn.ModuleList([\n",
        "            BTBADecoderLayer(config, is_last_layer=(i == config.decoder_layers - 1))\n",
        "            for i in range(config.decoder_layers)\n",
        "        ])\n"
      ],
      "metadata": {
        "id": "vVYAdMJb1s1X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BartForConditionalGeneration, BartConfig\n",
        "\n",
        "config = BartConfig.from_pretrained('facebook/bart-large')\n",
        "config.decoder_ffn_dim = 3072\n",
        "model = BartForConditionalGeneration(config)"
      ],
      "metadata": {
        "id": "6c4_MsZp3EOQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173,
          "referenced_widgets": [
            "ac685f4372f3409eb28a37af38f10994",
            "d3b61e7cd74d4717b8cfec3ee6f3c83b",
            "0fa27f80a1be45808fe760d6a854aa8a",
            "dfc99f599db545b2b6d970dd7add0145",
            "0b694989fb75498580950ef0b7d0befb",
            "8ecfc3ca273b48ca8f52bee363787d29",
            "36df467091864a90a24848057f19426e",
            "d59b176c198d4bbf89cd8c70c18f1064",
            "739a10bb3ba44d1ea8afd15be7d861d6",
            "c552229d16744199bf26a24d23b71a80",
            "a3efb5058d134c0d9d0e728516236dc2"
          ]
        },
        "outputId": "5bfba267-74b8-4dd1-9882-0215e710374f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/1.63k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ac685f4372f3409eb28a37af38f10994"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load unmodified BART"
      ],
      "metadata": {
        "id": "Nh_ow1gX-NNa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BartTokenizer, BartForConditionalGeneration\n",
        "\n",
        "model = BartForConditionalGeneration.from_pretrained('facebook/bart-large')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205,
          "referenced_widgets": [
            "93f8e63a111b43978dc59cc0d19f8b8c",
            "715996bfae3341f1bd6b22acb4b0ceb0",
            "580b6c7a96654ed0834d8782f88b07aa",
            "59ae5b46631146a888df73cc5dee286a",
            "e4aac4eafe40447ab93159895f9f5a01",
            "7de9ca9717df44eeac256ac3b5107752",
            "fb9815f28617477b9e8b55118a81f3e1",
            "e3fbd6a8262f4a50b791531ddd92925d",
            "cdffc55320a64dd683660dfb0130b6b4",
            "451421c0edd142d58ef3f1f67ab501e3",
            "03d3a268ec7b48a1b9f8aac570a18352",
            "272a680d71924bc9b19706222ea0e73a",
            "7dece1c9e4ea44ba9f78346ba6246274",
            "5be28e731cde40e482f3e7f67ddb60f3",
            "b684fe1ef2204f2a80f849556be010b1",
            "9950ec2dd4d346e28fd65c626f3cf621",
            "09a6ba553b2447a59876246a2c8e7ee7",
            "a02215234a0948ae8bdff0a1ad5dc17c",
            "25f268aea571434b93edb039cee36fa9",
            "4f2d81a528484ab4a7d1f2a48d049eb7",
            "3991e2a817034e47815ce5370cd9fb80",
            "3d4148ad975a4e5fbafbc946367051c1"
          ]
        },
        "id": "joKMMMAzwAbc",
        "outputId": "e1e6fa3e-dc95-4cb9-e46a-c7b3cc82300d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/1.63k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "93f8e63a111b43978dc59cc0d19f8b8c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/1.02G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "272a680d71924bc9b19706222ea0e73a"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# BTBA for original transformer model modification\n",
        "To perform training with the original transformer model\n",
        "*Requires a lot of memory"
      ],
      "metadata": {
        "id": "N5oo9KaGBRno"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import Transformer\n",
        "\n",
        "class CustomDecoderLayer(nn.TransformerDecoderLayer):\n",
        "    def __init__(self, d_model, nhead, dim_feedforward=2048, dropout=0.1, activation=\"relu\", is_last_layer=False):\n",
        "        super().__init__(d_model, nhead, dim_feedforward, dropout, activation)\n",
        "        self.is_last_layer = is_last_layer\n",
        "        if self.is_last_layer:\n",
        "            self.linear2 = None\n",
        "\n",
        "    def forward(self, tgt, memory, tgt_mask=None, memory_mask=None,\n",
        "                tgt_key_padding_mask=None, memory_key_padding_mask=None):\n",
        "        x = tgt\n",
        "        x = self.self_attn(x, x, x, attn_mask=tgt_mask,\n",
        "                           key_padding_mask=tgt_key_padding_mask)[0]\n",
        "        x = self.dropout1(x)\n",
        "        x = self.norm1(tgt + x)\n",
        "\n",
        "        x2 = self.multihead_attn(x, memory, memory, attn_mask=memory_mask,\n",
        "                                 key_padding_mask=memory_key_padding_mask)[0]\n",
        "        x = x + self.dropout2(x2)\n",
        "        x = self.norm2(x)\n",
        "\n",
        "        if not self.is_last_layer:\n",
        "            x2 = self.linear2(self.dropout(self.activation(self.linear1(x))))\n",
        "            x = x + self.dropout3(x2)\n",
        "            x = self.norm3(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "class CustomTransformerModel(nn.Module):\n",
        "    def __init__(self, d_model=512, nhead=8, num_encoder_layers=6, num_decoder_layers=6):\n",
        "        super().__init__()\n",
        "        self.transformer = Transformer(d_model=d_model, nhead=nhead, num_encoder_layers=num_encoder_layers, num_decoder_layers=num_decoder_layers)\n",
        "        self.transformer.decoder.layers = nn.ModuleList([\n",
        "            CustomDecoderLayer(d_model, nhead, is_last_layer=(i == num_decoder_layers - 1))\n",
        "            for i in range(num_decoder_layers)\n",
        "        ])\n",
        "\n",
        "    def forward(self, src, tgt, src_mask=None, tgt_mask=None, src_key_padding_mask=None, tgt_key_padding_mask=None):\n",
        "        return self.transformer(src, tgt, src_mask, tgt_mask, src_key_padding_mask, tgt_key_padding_mask)\n",
        "\n",
        "d_model = 512\n",
        "nhead = 8\n",
        "num_encoder_layers = 6\n",
        "num_decoder_layers = 6\n",
        "\n",
        "model = CustomTransformerModel(d_model, nhead, num_encoder_layers, num_decoder_layers)"
      ],
      "metadata": {
        "id": "Jb5Gq9RTBi--"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Collate function\n",
        "To accomodate for masking while training modified BART (Padding and masking properly)"
      ],
      "metadata": {
        "id": "CDNHEEbv-fX5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def collate_fn(batch):\n",
        "    input_ids = pad_sequence([item['input_ids'] for item in batch], batch_first=True, padding_value=tokenizer.pad_token_id)\n",
        "    labels = pad_sequence([item['labels'] for item in batch], batch_first=True, padding_value=-100)\n",
        "    attention_mask = input_ids.ne(tokenizer.pad_token_id).int()\n",
        "    return {'input_ids': input_ids, 'labels': labels, 'attention_mask': attention_mask}"
      ],
      "metadata": {
        "id": "AzILp-IarWoz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# FOR UNMODIFIED BART, TO TEST PERFORMANCE WITH JUST MASKING\n",
        "def collate_fn(batch):\n",
        "    pad_token_id = tokenizer.pad_token_id()\n",
        "    input_ids = pad_sequence([item['input_ids'] for item in batch], batch_first=True, padding_value=pad_token_id).to(device)\n",
        "    labels = pad_sequence([item['labels'] for item in batch], batch_first=True, padding_value=-100).to(device)\n",
        "    attention_mask = input_ids.ne(pad_token_id).int().to(device)\n",
        "    return {'input_ids': input_ids, 'labels': labels, 'attention_mask': attention_mask}"
      ],
      "metadata": {
        "id": "WHLI2td90I2F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Load data"
      ],
      "metadata": {
        "id": "4XOZ0Be2B9SY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "data_loader = DataLoader(dataset, batch_size=2, shuffle=False, collate_fn=collate_fn)\n",
        "\n",
        "for batch in data_loader:\n",
        "    print(\"Batch shapes and device:\")\n",
        "    print(\"Input IDs:\", batch['input_ids'].shape, batch['input_ids'].device)\n",
        "    print(\"Labels:\", batch['labels'].shape, batch['labels'].device)\n",
        "    print(\"Attention Masks:\", batch['attention_mask'].shape, batch['attention_mask'].device)\n",
        "\n",
        "    model = model.to(batch['input_ids'].device)\n",
        "    outputs = model(**batch)\n",
        "    print(\"Output Logits Shape:\", outputs.logits.shape)\n",
        "    break\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wVpW65GMTMXf",
        "outputId": "19c8b5bc-8f09-49fa-a225-78141a673f43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch shapes and device:\n",
            "Input IDs: torch.Size([2, 82]) cuda:0\n",
            "Labels: torch.Size([2, 82]) cuda:0\n",
            "Attention Masks: torch.Size([2, 82]) cuda:0\n",
            "Output Logits Shape: torch.Size([2, 82, 50265])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### For testing - subsample the data"
      ],
      "metadata": {
        "id": "nV_BabHTBBoZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Subset\n",
        "import multiprocessing\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "multiprocessing.set_start_method('spawn', force=True)\n",
        "\n",
        "def subsample_dataset(dataset, factor=10):\n",
        "    subset_indices = list(range(0, len(dataset), factor))\n",
        "    return Subset(dataset, subset_indices)\n",
        "\n",
        "subsampled_dataset = subsample_dataset(dataset, factor=400)\n",
        "\n",
        "data_loader = DataLoader(subsampled_dataset, batch_size=2, shuffle=False, collate_fn=collate_fn)\n"
      ],
      "metadata": {
        "id": "mlqJEKlrl_-j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Customize Trainer for BART models"
      ],
      "metadata": {
        "id": "-89ZXIC3CA4-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#BTBA/UNMODIFIED BART\n",
        "from torch.nn.functional import cross_entropy\n",
        "from transformers import Trainer, TrainingArguments\n",
        "\n",
        "class CustomTrainer(Trainer):\n",
        "    def compute_loss(self, model, inputs, return_outputs=False):\n",
        "        labels = inputs.pop(\"labels\", None)\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.logits\n",
        "\n",
        "        # Match the logits and labels lengths\n",
        "        if labels is not None and logits.size(1) != labels.size(1):\n",
        "            min_seq_len = min(logits.size(1), labels.size(1))\n",
        "            logits = logits[:, :min_seq_len, :].contiguous()\n",
        "            labels = labels[:, :min_seq_len].contiguous()\n",
        "\n",
        "        logits = logits.view(-1, logits.size(-1))\n",
        "        labels = labels.view(-1)\n",
        "\n",
        "        loss = cross_entropy(logits, labels, ignore_index=-100)\n",
        "        return (loss, outputs) if return_outputs else loss\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "EwlIU6V9GIok"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ORIGINAL TRANSFORMER MODEL\n",
        "from torch.nn.functional import cross_entropy\n",
        "from transformers import Trainer, TrainingArguments\n",
        "\n",
        "class CustomTrainer(Trainer):\n",
        "    def compute_loss(self, model, inputs, return_outputs=False):\n",
        "        labels = inputs.pop(\"labels\", None)\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.logits\n",
        "\n",
        "        if labels is not None and logits.size(1) != labels.size(1):\n",
        "            min_seq_len = min(logits.size(1), labels.size(1))\n",
        "            logits = logits[:, :min_seq_len, :].contiguous()\n",
        "            labels = labels[:, :min_seq_len].contiguous()\n",
        "\n",
        "        logits = logits.view(-1, logits.size(-1))\n",
        "        labels = labels.view(-1)\n",
        "        loss = cross_entropy(logits, labels, ignore_index=-100)\n",
        "        return (loss, outputs) if return_outputs else loss\n"
      ],
      "metadata": {
        "id": "OGsSRfN4rlmz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training and train parameters"
      ],
      "metadata": {
        "id": "VzICIwBkDzvb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# UNMODIFIED BART BART\n",
        "from transformers import Trainer, TrainingArguments\n",
        "from torch.utils.data import DataLoader\n",
        "import numpy as np\n",
        "import torch.multiprocessing as mp\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_strategy=\"no\",\n",
        "    learning_rate=3e-5,\n",
        "    per_device_train_batch_size=32,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.01,\n",
        "    load_best_model_at_end=False,\n",
        "    fp16=True,\n",
        "    report_to=\"none\"\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=dataset,\n",
        "    data_collator=collate_fn\n",
        ")\n",
        "\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "64se4S_ZxLoc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ORIGINAL TRANSFORMER MODEL BTBA\n",
        "\n",
        "from transformers import Trainer, TrainingArguments\n",
        "from torch.utils.data import DataLoader\n",
        "import numpy as np  # Ensure numpy is imported\n",
        "import torch.multiprocessing as mp\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    learning_rate=5e-5,\n",
        "    per_device_train_batch_size=16,\n",
        "    gradient_accumulation_steps=4,\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.01,\n",
        "    load_best_model_at_end=True,\n",
        "    fp16=True,\n",
        ")\n",
        "\n",
        "\n",
        "data_loader = DataLoader(\n",
        "    dataset,\n",
        "    batch_size=16,\n",
        "    shuffle=True,\n",
        "    num_workers=4,\n",
        "    pin_memory=True,\n",
        "    collate_fn=collate_fn\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "trainer = CustomTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=dataset,\n",
        "    data_collator=collate_fn,\n",
        ")\n",
        "\n",
        "trainer.train()\n"
      ],
      "metadata": {
        "id": "O40bT8gN245V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Total number of samples in dataset:\", len(dataset))\n",
        "print(\"Configured batch size:\", training_args.per_device_train_batch_size)\n",
        "print(\"Total number of batches per epoch:\", len(dataset) // training_args.per_device_train_batch_size)\n"
      ],
      "metadata": {
        "id": "g1UdaIDuVuWY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# BTBA BART TRAINING\n",
        "\n",
        "from transformers import Trainer, TrainingArguments\n",
        "from torch.utils.data import DataLoader\n",
        "import torch\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_strategy=\"no\",\n",
        "    learning_rate=3e-5,\n",
        "    per_device_train_batch_size=16,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.01,\n",
        "    load_best_model_at_end=False,\n",
        "    fp16=True,\n",
        "    report_to=\"none\"\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=subsampled_dataset,\n",
        "    data_collator=collate_fn\n",
        ")\n",
        "\n",
        "trainer.train()\n"
      ],
      "metadata": {
        "id": "V4W3UzNwVUDH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluate and test evaluation data\n",
        "* Use this data with your talp (gold alignments) data\n",
        "* Converts talp to expected AER and evaluation format."
      ],
      "metadata": {
        "id": "MrnOLTWBDeBH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_alignment_line(line):\n",
        "    sure_alignments = set()\n",
        "    possible_alignments = set()\n",
        "    for alignment in line.split():\n",
        "        # Check if alignment is marked as 'possible'\n",
        "        if 'p' in alignment:\n",
        "            src, tgt = alignment.replace('p', '-').split('-')\n",
        "            possible_alignments.add((int(src), int(tgt)))\n",
        "        else:\n",
        "            src, tgt = alignment.split('-')\n",
        "            sure_alignments.add((int(src), int(tgt)))\n",
        "            possible_alignments.add((int(src), int(tgt)))  # Include sure in possible\n",
        "\n",
        "    return sure_alignments, possible_alignments\n",
        "\n",
        "def process_talp_file(file_path):\n",
        "    gold_alignments = {'sure': set(), 'possible': set()}\n",
        "\n",
        "    with open(file_path, 'r') as file:\n",
        "        for line in file:\n",
        "            sure, possible = parse_alignment_line(line)\n",
        "            gold_alignments['sure'].update(sure)\n",
        "            gold_alignments['possible'].update(possible)\n",
        "\n",
        "    return gold_alignments\n",
        "\n",
        "alignment_file_path = '<PATH TO PAIR TEST TALP FILE>'\n",
        "gold_alignments = process_talp_file(alignment_file_path)\n",
        "print(gold_alignments['sure'])\n",
        "print(gold_alignments['possible'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NRsWzErt_oOM",
        "outputId": "7398fa64-ddde-4f94-c6a2-e1d4da4633b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{(15, 21), (26, 21), (18, 17), (7, 17), (26, 30), (15, 30), (18, 26), (26, 39), (29, 32), (8, 9), (19, 9), (11, 5), (8, 18), (19, 18), (11, 14), (11, 23), (33, 20), (33, 29), (10, 27), (25, 25), (4, 2), (33, 38), (25, 34), (3, 6), (22, 19), (14, 15), (3, 15), (22, 28), (34, 30), (14, 24), (15, 7), (7, 3), (15, 16), (26, 16), (7, 12), (18, 12), (15, 25), (26, 25), (18, 21), (7, 21), (18, 30), (29, 27), (8, 4), (29, 36), (30, 13), (21, 32), (11, 9), (10, 22), (33, 24), (25, 20), (33, 33), (25, 29), (22, 5), (25, 38), (3, 1), (14, 1), (22, 14), (34, 16), (14, 10), (3, 10), (34, 25), (22, 23), (14, 19), (22, 32), (37, 30), (14, 28), (15, 2), (36, 34), (15, 11), (7, 7), (18, 7), (26, 20), (7, 16), (18, 16), (29, 22), (21, 18), (29, 31), (21, 27), (11, 4), (40, 40), (10, 8), (10, 17), (25, 15), (2, 13), (10, 26), (33, 28), (25, 24), (33, 37), (25, 33), (3, 5), (14, 5), (22, 18), (14, 14), (3, 14), (22, 27), (14, 23), (36, 29), (15, 6), (17, 25), (28, 25), (7, 2), (18, 2), (28, 34), (7, 11), (18, 11), (6, 15), (29, 17), (21, 13), (29, 26), (21, 22), (29, 35), (21, 31), (10, 3), (10, 12), (2, 8), (10, 21), (33, 23), (25, 19), (25, 28), (22, 4), (32, 36), (22, 13), (24, 32), (3, 9), (14, 9), (14, 18), (26, 1), (17, 20), (36, 33), (28, 29), (17, 29), (9, 25), (28, 38), (6, 10), (21, 8), (29, 21), (21, 17), (21, 26), (10, 7), (2, 3), (10, 16), (2, 12), (25, 14), (10, 25), (2, 21), (32, 31), (24, 27), (35, 27), (3, 4), (14, 4), (13, 27), (24, 36), (35, 36), (17, 6), (17, 15), (36, 28), (9, 11), (28, 24), (17, 24), (36, 37), (9, 20), (28, 33), (17, 33), (6, 5), (6, 14), (21, 12), (29, 25), (21, 21), (21, 30), (10, 2), (31, 34), (10, 11), (2, 7), (13, 13), (24, 13), (13, 22), (24, 22), (32, 35), (16, 18), (24, 31), (16, 27), (35, 40), (17, 1), (17, 10), (5, 8), (9, 6), (17, 19), (5, 17), (28, 19), (9, 15), (36, 32), (28, 28), (17, 28), (9, 24), (28, 37), (6, 9), (21, 7), (6, 18), (21, 16), (20, 20), (20, 29), (31, 29), (10, 6), (12, 25), (23, 25), (2, 2), (31, 38), (23, 34), (2, 11), (13, 8), (24, 8), (13, 17), (1, 15), (32, 30), (16, 13), (24, 17), (24, 26), (35, 26), (32, 39), (16, 22), (35, 17), (13, 26), (5, 3), (17, 5), (36, 18), (9, 1), (17, 14), (5, 12), (9, 10), (28, 23), (17, 23), (9, 19), (6, 4), (21, 2), (6, 13), (19, 32), (20, 15), (31, 15), (20, 24), (31, 24), (23, 20), (12, 20), (31, 33), (23, 29), (12, 29), (32, 7), (13, 3), (13, 12), (1, 10), (32, 25), (16, 8), (13, 21), (24, 21), (16, 17), (35, 30), (24, 30), (13, 30), (16, 26), (5, 7), (17, 9), (9, 5), (5, 16), (28, 18), (9, 14), (27, 22), (27, 31), (30, 27), (19, 27), (30, 36), (20, 1), (20, 10), (12, 6), (20, 19), (12, 15), (23, 15), (20, 28), (4, 11), (31, 28), (23, 24), (12, 24), (31, 37), (23, 33), (1, 5), (24, 7), (13, 7), (13, 16), (24, 16), (1, 14), (16, 12), (24, 25), (35, 25), (16, 21), (16, 30), (5, 2), (28, 4), (26, 34), (38, 36), (5, 11), (9, 9), (27, 17), (8, 13), (19, 13), (27, 26), (19, 22), (30, 22), (27, 35), (11, 18), (19, 31), (30, 31), (20, 5), (20, 14), (31, 14), (39, 27), (12, 10), (23, 10), (20, 23), (4, 6), (31, 23), (12, 19), (23, 19), (20, 32), (4, 15), (31, 32), (23, 28), (13, 2), (13, 11), (1, 9), (24, 11), (16, 7), (16, 16), (15, 20), (26, 29), (15, 29), (5, 6), (18, 25), (26, 38), (8, 8), (19, 8), (27, 21), (8, 17), (19, 17), (27, 30), (11, 13), (19, 26), (30, 26), (11, 22), (30, 35), (20, 9), (12, 5), (20, 18), (4, 1), (12, 14), (23, 14), (4, 10), (23, 23), (12, 23), (35, 6), (1, 4), (16, 2), (34, 38), (1, 13), (26, 15), (15, 15), (26, 24), (15, 24), (7, 20), (18, 20), (26, 33), (38, 35), (18, 29), (8, 3), (27, 16), (8, 12), (19, 12), (27, 25), (11, 8), (19, 21), (30, 21), (11, 17), (30, 30), (19, 30), (20, 4), (20, 13), (33, 32), (12, 9), (4, 5), (23, 18), (25, 37), (4, 14), (22, 22), (34, 24), (22, 31), (34, 33), (37, 29), (37, 38), (15, 1), (15, 10), (7, 6), (18, 6), (15, 19), (26, 19), (18, 15), (7, 15), (26, 28), (38, 30), (15, 28), (18, 24), (27, 2), (18, 33), (8, 7), (19, 7), (27, 20), (11, 3), (40, 39), (19, 16), (8, 16), (29, 39), (11, 12), (30, 16), (19, 25), (30, 25), (11, 21), (12, 4), (25, 23), (33, 36), (25, 32), (4, 9), (22, 17), (3, 13), (14, 13), (22, 26), (34, 28), (14, 22), (22, 35), (34, 37), (15, 5), (26, 5), (7, 1), (15, 14), (26, 14), (7, 10), (18, 10), (26, 23), (15, 23), (18, 19), (7, 19), (26, 32), (18, 28), (8, 2), (29, 34), (8, 11), (19, 11), (11, 7), (11, 16), (10, 20), (33, 22), (25, 18), (33, 31), (25, 27), (33, 40), (22, 12), (3, 8), (14, 8), (22, 21), (34, 23), (14, 17), (22, 30), (37, 28), (14, 26), (15, 9), (7, 5), (18, 5), (15, 18), (26, 18), (7, 14), (18, 14), (18, 23), (29, 20), (29, 29), (30, 6), (21, 25), (19, 6), (29, 38), (21, 34), (25, 4), (10, 15), (25, 13), (33, 26), (25, 22), (25, 31), (34, 9), (22, 7), (3, 3), (14, 3), (22, 16), (14, 12), (3, 12), (22, 25), (14, 21), (37, 23), (36, 27), (15, 4), (26, 4), (36, 36), (15, 13), (28, 32), (26, 13), (7, 9), (18, 9), (18, 18), (21, 11), (21, 20), (29, 33), (21, 29), (10, 1), (10, 10), (2, 6), (10, 19), (7, 8), (33, 21), (25, 17), (2, 15), (33, 30), (25, 26), (25, 35), (32, 34), (3, 7), (14, 7), (22, 20), (35, 39), (14, 16), (3, 16), (17, 18), (28, 27), (17, 27), (7, 4), (36, 40), (18, 4), (6, 8), (6, 17), (29, 19), (21, 15), (29, 28), (21, 24), (29, 37), (10, 5), (2, 1), (25, 3), (10, 14), (33, 16), (2, 10), (25, 21), (32, 29), (22, 6), (13, 25), (3, 2), (32, 38), (14, 2), (35, 34), (24, 34), (14, 11), (3, 11), (36, 17), (17, 13), (17, 22), (28, 22), (36, 35), (9, 18), (28, 31), (17, 31), (28, 40), (6, 3), (29, 5), (6, 12), (21, 10), (29, 23), (21, 19), (21, 28), (10, 9), (2, 5), (25, 7), (10, 18), (25, 16), (32, 15), (32, 24), (22, 1), (13, 20), (24, 20), (32, 33), (24, 29), (14, 6), (16, 25), (17, 8), (28, 8), (9, 4), (17, 17), (5, 15), (28, 17), (9, 13), (36, 30), (17, 26), (28, 26), (36, 39), (28, 35), (6, 7), (29, 9), (21, 5), (6, 16), (21, 14), (21, 23), (20, 27), (31, 27), (10, 4), (31, 36), (10, 13), (23, 32), (2, 9), (13, 6), (13, 15), (24, 15), (32, 28), (16, 11), (13, 24), (24, 24), (32, 37), (16, 20), (24, 33), (35, 33), (5, 1), (28, 3), (17, 3), (17, 12), (5, 10), (28, 12), (9, 8), (17, 21), (5, 19), (28, 21), (9, 17), (28, 30), (17, 30), (6, 2), (27, 34), (6, 11), (21, 9), (6, 20), (20, 22), (39, 35), (12, 18), (31, 31), (20, 31), (23, 27), (12, 27), (2, 4), (13, 10), (1, 8), (32, 23), (16, 6), (24, 19), (13, 19), (1, 17), (16, 15), (32, 32), (24, 28), (35, 28), (13, 28), (16, 24), (5, 5), (17, 7), (28, 7), (9, 3), (17, 16), (5, 14), (28, 16), (9, 12), (9, 21), (27, 29), (6, 6), (21, 4), (30, 34), (19, 34), (20, 8), (20, 17), (12, 13), (23, 13), (20, 26), (31, 26), (23, 22), (12, 22), (31, 35), (4, 18), (23, 31), (1, 3), (13, 5), (16, 1), (13, 14), (24, 14), (1, 12), (16, 10), (13, 23), (24, 23), (16, 19), (35, 32), (16, 28), (17, 11), (5, 9), (9, 7), (9, 16), (27, 24), (6, 1), (19, 20), (8, 20), (27, 33), (19, 29), (30, 29), (30, 38), (20, 12), (31, 12), (12, 8), (23, 8), (20, 21), (4, 4), (12, 17), (23, 17), (20, 30), (4, 13), (31, 30), (23, 26), (12, 26), (31, 39), (23, 35), (34, 32), (13, 9), (1, 7), (16, 5), (24, 18), (13, 18), (1, 16), (16, 14), (35, 18), (16, 23), (15, 27), (26, 27), (5, 4), (38, 29), (9, 2), (5, 13), (8, 6), (27, 19), (8, 15), (19, 15), (27, 28), (11, 11), (30, 15), (19, 24), (8, 24), (30, 24), (11, 20), (19, 33), (30, 33), (31, 7), (12, 3), (20, 16), (12, 12), (23, 12), (20, 25), (4, 8), (31, 25), (23, 21), (12, 21), (4, 17), (23, 30), (34, 27), (1, 2), (13, 4), (22, 34), (34, 36), (16, 9), (26, 22), (15, 22), (26, 31), (18, 27), (8, 1), (19, 1), (27, 14), (8, 10), (19, 10), (30, 10), (11, 6), (27, 23), (19, 19), (8, 19), (27, 32), (11, 15), (19, 28), (30, 28), (11, 24), (30, 37), (20, 2), (20, 11), (12, 7), (23, 7), (4, 3), (33, 39), (12, 16), (23, 16), (4, 12), (34, 22), (37, 18), (22, 29), (34, 31), (1, 6), (37, 27), (34, 40), (16, 4), (37, 36), (15, 8), (15, 17), (26, 17), (7, 13), (18, 13), (26, 26), (38, 28), (18, 22), (26, 35), (38, 37), (18, 31), (27, 9), (8, 5), (27, 18), (11, 1), (19, 14), (8, 14), (27, 27), (11, 10), (30, 14), (19, 23), (8, 23), (11, 19), (30, 32), (20, 6), (33, 25), (12, 2), (12, 11), (25, 30), (23, 11), (4, 7), (34, 8), (22, 15), (34, 26), (22, 24), (1, 1), (14, 20), (34, 35), (22, 33), (37, 31), (14, 29), (37, 40), (15, 3), (15, 12), (18, 8)}\n",
            "{(15, 21), (26, 21), (38, 23), (18, 17), (7, 17), (26, 30), (15, 30), (18, 26), (26, 39), (29, 32), (8, 9), (19, 9), (11, 5), (8, 18), (19, 18), (11, 14), (11, 23), (33, 20), (33, 29), (10, 27), (25, 25), (4, 2), (33, 38), (25, 34), (3, 6), (22, 19), (14, 15), (3, 15), (22, 28), (34, 30), (14, 24), (15, 7), (7, 3), (15, 16), (26, 16), (7, 12), (18, 12), (15, 25), (26, 25), (18, 21), (7, 21), (18, 30), (29, 27), (8, 4), (29, 36), (30, 13), (21, 32), (11, 9), (10, 22), (33, 24), (25, 20), (33, 33), (25, 29), (22, 5), (25, 38), (3, 1), (14, 1), (22, 14), (34, 16), (14, 10), (3, 10), (34, 25), (22, 23), (14, 19), (22, 32), (37, 30), (14, 28), (15, 2), (36, 34), (15, 11), (7, 7), (18, 7), (26, 20), (7, 16), (18, 16), (29, 22), (21, 18), (29, 31), (21, 27), (11, 4), (40, 40), (10, 8), (10, 17), (25, 15), (2, 13), (10, 26), (33, 28), (25, 24), (33, 37), (25, 33), (3, 5), (14, 5), (22, 18), (14, 14), (3, 14), (22, 27), (14, 23), (36, 29), (15, 6), (17, 25), (28, 25), (7, 2), (18, 2), (28, 34), (7, 11), (18, 11), (6, 15), (29, 17), (21, 13), (29, 26), (21, 22), (29, 35), (21, 31), (10, 3), (10, 12), (2, 8), (10, 21), (33, 23), (25, 19), (25, 28), (22, 4), (32, 36), (22, 13), (24, 32), (3, 9), (14, 9), (14, 18), (26, 1), (17, 20), (36, 33), (28, 29), (17, 29), (9, 25), (28, 38), (6, 10), (21, 8), (29, 21), (21, 17), (29, 30), (21, 26), (10, 7), (2, 3), (10, 16), (2, 12), (25, 14), (10, 25), (2, 21), (32, 31), (24, 27), (35, 27), (3, 4), (14, 4), (13, 27), (24, 36), (35, 36), (17, 6), (17, 15), (36, 28), (9, 11), (28, 24), (17, 24), (36, 37), (9, 20), (28, 33), (17, 33), (6, 5), (6, 14), (29, 16), (21, 12), (29, 25), (21, 21), (21, 30), (10, 2), (31, 34), (10, 11), (2, 7), (13, 13), (24, 13), (13, 22), (24, 22), (32, 35), (16, 18), (24, 31), (16, 27), (35, 40), (17, 1), (5, 8), (17, 10), (9, 6), (17, 19), (5, 17), (28, 19), (9, 15), (36, 32), (28, 28), (17, 28), (9, 24), (28, 37), (6, 9), (21, 7), (6, 18), (21, 16), (20, 20), (20, 29), (31, 29), (10, 6), (12, 25), (23, 25), (2, 2), (31, 38), (23, 34), (2, 11), (13, 8), (24, 8), (13, 17), (1, 15), (32, 30), (16, 13), (24, 17), (24, 26), (35, 26), (32, 39), (16, 22), (35, 17), (13, 26), (5, 3), (17, 5), (36, 18), (9, 1), (17, 14), (5, 12), (9, 10), (28, 23), (17, 23), (9, 19), (6, 4), (21, 2), (6, 13), (19, 32), (20, 15), (31, 15), (20, 24), (31, 24), (23, 20), (12, 20), (31, 33), (23, 29), (12, 29), (32, 7), (13, 3), (13, 12), (1, 10), (32, 25), (16, 8), (13, 21), (24, 21), (16, 17), (35, 30), (24, 30), (13, 30), (16, 26), (5, 7), (17, 9), (9, 5), (5, 16), (28, 18), (9, 14), (27, 22), (27, 31), (30, 27), (19, 27), (30, 36), (20, 1), (20, 10), (12, 6), (23, 6), (20, 19), (12, 15), (23, 15), (20, 28), (4, 11), (31, 28), (23, 24), (12, 24), (31, 37), (4, 20), (23, 33), (1, 5), (24, 7), (13, 7), (13, 16), (24, 16), (1, 14), (16, 12), (24, 25), (35, 25), (16, 21), (16, 30), (5, 2), (28, 4), (26, 34), (38, 36), (5, 11), (9, 9), (27, 17), (8, 13), (19, 13), (27, 26), (19, 22), (30, 22), (27, 35), (11, 18), (19, 31), (30, 31), (20, 5), (20, 14), (31, 14), (39, 27), (12, 10), (23, 10), (20, 23), (4, 6), (31, 23), (12, 19), (23, 19), (20, 32), (4, 15), (31, 32), (23, 28), (13, 2), (34, 34), (13, 11), (1, 9), (24, 11), (16, 7), (16, 16), (15, 20), (26, 29), (15, 29), (5, 6), (18, 25), (26, 38), (8, 8), (19, 8), (27, 21), (8, 17), (19, 17), (27, 30), (11, 13), (30, 17), (19, 26), (30, 26), (11, 22), (30, 35), (20, 9), (12, 5), (23, 5), (20, 18), (4, 1), (12, 14), (23, 14), (4, 10), (23, 23), (12, 23), (35, 6), (1, 4), (16, 2), (34, 38), (1, 13), (26, 15), (15, 15), (26, 24), (15, 24), (7, 20), (18, 20), (26, 33), (38, 35), (18, 29), (8, 3), (27, 16), (8, 12), (19, 12), (27, 25), (11, 8), (19, 21), (30, 21), (11, 17), (30, 30), (19, 30), (20, 4), (20, 13), (33, 32), (12, 9), (23, 9), (4, 5), (23, 18), (25, 37), (4, 14), (22, 22), (34, 24), (22, 31), (34, 33), (37, 29), (37, 38), (15, 1), (15, 10), (7, 6), (18, 6), (15, 19), (26, 19), (18, 15), (7, 15), (26, 28), (38, 30), (15, 28), (18, 24), (27, 2), (18, 33), (8, 7), (19, 7), (27, 20), (11, 3), (40, 39), (19, 16), (8, 16), (29, 39), (11, 12), (30, 16), (19, 25), (30, 25), (11, 21), (12, 4), (25, 23), (23, 4), (33, 36), (25, 32), (4, 9), (22, 17), (3, 13), (14, 13), (22, 26), (34, 28), (14, 22), (22, 35), (34, 37), (15, 5), (26, 5), (7, 1), (15, 14), (26, 14), (7, 10), (18, 10), (26, 23), (15, 23), (18, 19), (7, 19), (26, 32), (18, 28), (8, 2), (29, 34), (8, 11), (19, 11), (11, 7), (11, 16), (10, 20), (33, 22), (25, 18), (33, 31), (25, 27), (33, 40), (22, 12), (14, 8), (3, 8), (22, 21), (34, 23), (14, 17), (22, 30), (37, 28), (14, 26), (15, 9), (7, 5), (18, 5), (15, 18), (26, 18), (7, 14), (18, 14), (18, 23), (29, 20), (29, 29), (30, 6), (21, 25), (19, 6), (29, 38), (21, 34), (25, 4), (10, 15), (25, 13), (33, 26), (25, 22), (25, 31), (34, 9), (22, 7), (3, 3), (14, 3), (22, 16), (14, 12), (3, 12), (22, 25), (14, 21), (37, 23), (36, 27), (15, 4), (26, 4), (36, 36), (15, 13), (28, 32), (26, 13), (7, 9), (18, 9), (18, 18), (21, 11), (29, 24), (21, 20), (29, 33), (21, 29), (10, 1), (10, 10), (2, 6), (10, 19), (7, 8), (33, 21), (25, 17), (2, 15), (33, 30), (25, 26), (25, 35), (32, 34), (3, 7), (14, 7), (22, 20), (35, 39), (14, 16), (3, 16), (17, 18), (28, 27), (17, 27), (7, 4), (36, 40), (18, 4), (26, 12), (6, 8), (21, 6), (6, 17), (29, 19), (21, 15), (29, 28), (21, 24), (29, 37), (10, 5), (33, 7), (2, 1), (25, 3), (10, 14), (33, 16), (2, 10), (25, 12), (25, 21), (32, 29), (22, 6), (13, 25), (3, 2), (32, 38), (14, 2), (35, 34), (24, 34), (14, 11), (3, 11), (36, 17), (17, 13), (17, 22), (28, 22), (36, 35), (9, 18), (28, 31), (17, 31), (28, 40), (6, 3), (29, 5), (6, 12), (21, 10), (29, 23), (21, 19), (21, 28), (10, 9), (2, 5), (25, 7), (10, 18), (25, 16), (32, 15), (32, 24), (22, 1), (13, 20), (24, 20), (32, 33), (24, 29), (14, 6), (16, 25), (17, 8), (28, 8), (9, 4), (17, 17), (5, 15), (28, 17), (9, 13), (36, 30), (17, 26), (28, 26), (36, 39), (28, 35), (6, 7), (29, 9), (21, 5), (6, 16), (21, 14), (21, 23), (20, 27), (31, 27), (10, 4), (31, 36), (10, 13), (23, 32), (2, 9), (13, 6), (13, 15), (24, 15), (32, 28), (16, 11), (13, 24), (24, 24), (32, 37), (16, 20), (24, 33), (35, 33), (5, 1), (28, 3), (17, 3), (17, 12), (5, 10), (36, 25), (9, 8), (28, 12), (17, 21), (5, 19), (28, 21), (9, 17), (28, 30), (17, 30), (6, 2), (27, 34), (6, 11), (21, 9), (6, 20), (20, 22), (39, 35), (12, 18), (31, 31), (20, 31), (23, 27), (12, 27), (2, 4), (13, 1), (13, 10), (24, 10), (32, 23), (16, 6), (1, 8), (24, 19), (13, 19), (1, 17), (16, 15), (32, 32), (24, 28), (35, 28), (13, 28), (16, 24), (35, 37), (5, 5), (17, 7), (28, 7), (9, 3), (17, 16), (5, 14), (28, 16), (9, 12), (9, 21), (27, 29), (6, 6), (21, 4), (30, 34), (19, 34), (20, 8), (20, 17), (12, 13), (23, 13), (20, 26), (31, 26), (23, 22), (12, 22), (31, 35), (4, 18), (23, 31), (1, 3), (13, 5), (16, 1), (13, 14), (24, 14), (1, 12), (16, 10), (13, 23), (24, 23), (16, 19), (35, 32), (16, 28), (17, 11), (5, 9), (9, 7), (9, 16), (27, 24), (6, 1), (19, 20), (8, 20), (27, 33), (19, 29), (30, 29), (30, 38), (20, 12), (31, 12), (12, 8), (23, 8), (20, 21), (4, 4), (12, 17), (23, 17), (20, 30), (4, 13), (31, 30), (23, 26), (12, 26), (31, 39), (23, 35), (34, 32), (13, 9), (1, 7), (16, 5), (24, 18), (13, 18), (1, 16), (16, 14), (35, 18), (16, 23), (15, 27), (26, 27), (5, 4), (38, 29), (9, 2), (5, 13), (8, 6), (27, 19), (8, 15), (19, 15), (27, 28), (11, 11), (30, 15), (19, 24), (8, 24), (30, 24), (11, 20), (19, 33), (30, 33), (31, 7), (20, 7), (12, 3), (20, 16), (12, 12), (23, 12), (20, 25), (4, 8), (31, 25), (23, 21), (12, 21), (4, 17), (23, 30), (34, 27), (1, 2), (13, 4), (22, 34), (34, 36), (1, 11), (16, 9), (26, 22), (15, 22), (7, 18), (26, 31), (18, 27), (8, 1), (19, 1), (27, 14), (8, 10), (19, 10), (30, 10), (11, 6), (27, 23), (19, 19), (8, 19), (27, 32), (11, 15), (19, 28), (30, 28), (11, 24), (30, 37), (20, 2), (20, 11), (12, 7), (23, 7), (4, 3), (33, 39), (12, 16), (23, 16), (4, 12), (4, 21), (34, 22), (37, 18), (22, 29), (34, 31), (1, 6), (37, 27), (34, 40), (16, 4), (37, 36), (15, 8), (15, 17), (26, 17), (7, 13), (18, 13), (26, 26), (38, 28), (18, 22), (26, 35), (38, 37), (18, 31), (27, 9), (8, 5), (27, 18), (11, 1), (19, 14), (8, 14), (27, 27), (11, 10), (30, 14), (19, 23), (8, 23), (11, 19), (30, 32), (20, 6), (33, 25), (12, 2), (33, 34), (12, 11), (25, 30), (23, 11), (4, 7), (34, 8), (22, 15), (34, 26), (22, 24), (1, 1), (14, 20), (34, 35), (22, 33), (37, 31), (14, 29), (37, 40), (15, 3), (15, 12), (18, 8)}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_aer(predicted_alignments, gold_alignments):\n",
        "    sure = set(gold_alignments['sure'])\n",
        "    possible = set(gold_alignments['possible']).union(sure)\n",
        "    predicted = set(predicted_alignments)\n",
        "\n",
        "    num_predicted = len(predicted)\n",
        "    num_sure = len(sure)\n",
        "    num_possible = len(possible)\n",
        "    num_correct_predicted = len(predicted.intersection(possible))\n",
        "    num_correct_sure = len(predicted.intersection(sure))\n",
        "\n",
        "    precision = num_correct_predicted / num_predicted if num_predicted > 0 else 0\n",
        "    recall = num_correct_sure / num_sure if num_sure > 0 else 0\n",
        "    aer = 1 - (num_correct_predicted + num_correct_sure) / (num_predicted + num_sure)\n",
        "\n",
        "    return aer, precision, recall\n",
        "\n",
        "class CustomTrainer(Trainer):\n",
        "    def evaluate(self, eval_dataset=None, ignore_keys=None, metric_key_prefix: str = \"eval\"):\n",
        "        eval_dataset = eval_dataset if eval_dataset is not None else self.eval_dataset\n",
        "        if eval_dataset is None:\n",
        "            raise ValueError(\"Trainer: evaluation requires an eval_dataset.\")\n",
        "\n",
        "        eval_dataloader = self.get_eval_dataloader(eval_dataset)\n",
        "\n",
        "        total_aer = 0\n",
        "        total_precision = 0\n",
        "        total_recall = 0\n",
        "        num_batches = 0\n",
        "\n",
        "        for batch in eval_dataloader:\n",
        "            batch = {k: v.to(self.args.device) for k, v in batch.items()}\n",
        "            with torch.no_grad():\n",
        "                outputs = self.model(**batch)\n",
        "\n",
        "            predicted_alignments = self.get_predicted_alignments(outputs)\n",
        "\n",
        "            if num_batches < len(gold_alignments):\n",
        "                gold_alignments_batch = gold_alignments[num_batches]\n",
        "            else:\n",
        "                continue  # Or handle the case where there's no corresponding gold data\n",
        "\n",
        "            aer, precision, recall = calculate_aer(predicted_alignments, gold_alignments_batch)\n",
        "            total_aer += aer\n",
        "            total_precision += precision\n",
        "            total_recall += recall\n",
        "            num_batches += 1\n",
        "\n",
        "        avg_aer = total_aer / num_batches\n",
        "        avg_precision = total_precision / num_batches\n",
        "        avg_recall = total_recall / num_batches\n",
        "\n",
        "        metrics = {\n",
        "            f\"{metric_key_prefix}_aer\": avg_aer,\n",
        "            f\"{metric_key_prefix}_precision\": avg_precision,\n",
        "            f\"{metric_key_prefix}_recall\": avg_recall\n",
        "        }\n",
        "\n",
        "        self.log(metrics)\n",
        "        return metrics\n",
        "\n",
        "    def get_predicted_alignments(self, outputs):\n",
        "        predicted_alignments = set()\n",
        "        if 'alignment' in outputs:\n",
        "            alignments = outputs['alignment']\n",
        "            for pair in alignments:\n",
        "                predicted_alignments.add((pair[0].item(), pair[1].item()))  # Example conversion from tensor\n",
        "        return predicted_alignments\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"no\",\n",
        "    learning_rate=3e-5,\n",
        "    per_device_train_batch_size=16,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.01,\n",
        "    load_best_model_at_end=False,\n",
        "    fp16=True,\n",
        "    report_to=\"none\"\n",
        ")\n",
        "\n",
        "trainer = CustomTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=subsampled_dataset,\n",
        "    eval_dataset=eval_dataset,\n",
        "    data_collator=collate_fn\n",
        ")\n",
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 953
        },
        "id": "4TkVNCuv6Vv-",
        "outputId": "5fb71745-1282-4fd5-b48e-aca41a8f97bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='301' max='900' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [301/900 00:42 < 01:24, 7.05 it/s, Epoch 1/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "0",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-e2c10e6733a4>\u001b[0m in \u001b[0;36m<cell line: 98>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0mdata_collator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m )\n\u001b[0;32m---> 98\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1930\u001b[0m                 \u001b[0mhf_hub_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_progress_bars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1931\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1932\u001b[0;31m             return inner_training_loop(\n\u001b[0m\u001b[1;32m   1933\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1934\u001b[0m                 \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2364\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2365\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_log_save_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_keys_for_eval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2366\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2367\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mDebugOption\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTPU_METRICS_DEBUG\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_maybe_log_save_evaluate\u001b[0;34m(self, tr_loss, grad_norm, model, trial, epoch, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2791\u001b[0m         \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2792\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_evaluate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2793\u001b[0;31m             \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_keys_for_eval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2794\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2795\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_save\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_evaluate\u001b[0;34m(self, trial, ignore_keys_for_eval, skip_scheduler)\u001b[0m\n\u001b[1;32m   2748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2749\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_keys_for_eval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_scheduler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2750\u001b[0;31m         \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mignore_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore_keys_for_eval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2751\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_report_to_hp_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2752\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-26-e2c10e6733a4>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, eval_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mnum_batches\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgold_alignments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m                 \u001b[0mgold_alignments_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgold_alignments\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnum_batches\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m                 \u001b[0;32mcontinue\u001b[0m  \u001b[0;31m# Or handle the case where there's no corresponding gold data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 0"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_with_talp(model, tokenizer, data_loader, device):\n",
        "    model.eval()\n",
        "    model.to(device)\n",
        "    alignments = []\n",
        "    with torch.no_grad():\n",
        "        for batch in data_loader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            outputs = model(input_ids)\n",
        "            generated_tokens = torch.argmax(outputs.logits, dim=-1)\n",
        "            alignments.extend(process_alignment_data(generated_tokens, tokenizer))\n",
        "    return alignments\n",
        "\n",
        "def process_alignment_data(generated_tokens, tokenizer):\n",
        "    return [tokenizer.convert_ids_to_tokens(g) for g in generated_tokens]\n"
      ],
      "metadata": {
        "id": "FUW0XXRq450F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Optimizations\n",
        "* FCBO parameter freezing\n",
        "* Symmetrize and train on labels"
      ],
      "metadata": {
        "id": "r8cr9DWWDRUt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def full_context_based_optimization(model, train_dataloader, optimizer, scheduler, device, num_iterations=50):\n",
        "    model.train()\n",
        "    for iteration in range(num_iterations):\n",
        "        for batch in train_dataloader:\n",
        "            input_ids, labels = batch['input_ids'].to(device), batch['labels'].to(device)\n",
        "            outputs = model(input_ids, labels=labels)\n",
        "            loss = outputs.loss\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "            optimizer.zero_grad()\n"
      ],
      "metadata": {
        "id": "dN3eMzWn49E1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def grow_diagonal_final_and(alignments_lr, alignments_rl):\n",
        "    \"\"\"\n",
        "    Symmetrize alignments using the grow-diagonal-final-and heuristic.\n",
        "    :param alignments_lr: List of alignments from left-to-right model\n",
        "    :param alignments_rl: List of alignments from right-to-left model\n",
        "    :return: Symmetrized alignments\n",
        "    \"\"\"\n",
        "    alignments = set(alignments_lr).intersection(set(alignments_rl))\n",
        "    alignments.update(set(alignments_lr).difference(set(alignments_rl)))\n",
        "    alignments.update(set(alignments_rl).difference(set(alignments_lr)))\n",
        "\n",
        "    def grow_diagonal(alignments):\n",
        "        grown_alignments = set(alignments)\n",
        "        for (i, j) in alignments:\n",
        "            for (di, dj) in [(0, 1), (1, 0), (1, 1), (-1, -1)]:\n",
        "                if (i + di, j + dj) in alignments_lr or (i + di, j + dj) in alignments_rl:\n",
        "                    grown_alignments.add((i + di, j + dj))\n",
        "        return grown_alignments\n",
        "\n",
        "    alignments = grow_diagonal(alignments)\n",
        "    return alignments"
      ],
      "metadata": {
        "id": "894-3JOg4_tH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage:\n",
        "alignments_lr = [(0, 0), (1, 1), (2, 2)]\n",
        "alignments_rl = [(0, 0), (1, 1), (2, 3)]\n",
        "\n",
        "symmetrized_alignments = grow_diagonal_final_and(alignments_lr, alignments_rl)\n",
        "print(symmetrized_alignments)"
      ],
      "metadata": {
        "id": "nz9dumYmDQYf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cleanup memory for subsequent runs"
      ],
      "metadata": {
        "id": "k6q7J5_b47nG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "8tBYAa28g4Lu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}